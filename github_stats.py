#!/usr/bin/python3

import asyncio
import os
import calendar
import math
from typing import Dict, List, Optional, Set, Tuple, Any, cast
from datetime import datetime
from cache_utils import (
    load_cache,
    save_cache,
    get_lines_changed,
    set_lines_changed,
    get_recent_commits,
    set_recent_commits,
)

import aiohttp
import requests


###############################################################################
# Main Classes
###############################################################################


class Queries(object):
    """
    Class with functions to query the GitHub GraphQL (v4) API and the REST (v3)
    API. Also includes functions to dynamically generate GraphQL queries.
    """

    def __init__(
        self,
        username: str,
        access_token: str,
        session: aiohttp.ClientSession,
        max_connections: int = 10,
    ):
        self.username = username
        self.access_token = access_token
        self.session = session
        self.semaphore = asyncio.Semaphore(max_connections)

    async def query(self, generated_query: str) -> Dict:
        """
        Make a request to the GraphQL API using the authentication token from
        the environment
        :param generated_query: string query to be sent to the API
        :return: decoded GraphQL JSON output
        """
        headers = {
            "Authorization": f"Bearer {self.access_token}",
        }
        try:
            async with self.semaphore:
                r_async = await self.session.post(
                    "https://api.github.com/graphql",
                    headers=headers,
                    json={"query": generated_query},
                )
            result = await r_async.json()
            if result is not None:
                return result
        except:
            print("aiohttp failed for GraphQL query")
            # Fall back on non-async requests
            async with self.semaphore:
                r_requests = requests.post(
                    "https://api.github.com/graphql",
                    headers=headers,
                    json={"query": generated_query},
                )
                result = r_requests.json()
                if result is not None:
                    return result
        return dict()

    async def query_rest(self, path: str, params: Optional[Dict] = None) -> Dict:
        """
        Make a request to the REST API
        :param path: API path to query
        :param params: Query parameters to be passed to the API
        :return: deserialized REST JSON output
        """

        for _ in range(60):
            headers = {
                "Authorization": f"token {self.access_token}",
            }
            if params is None:
                params = dict()
            if path.startswith("/"):
                path = path[1:]
            try:
                async with self.semaphore:
                    r_async = await self.session.get(
                        f"https://api.github.com/{path}",
                        headers=headers,
                        params=tuple(params.items()),
                    )
                if r_async.status == 202:
                    # print(f"{path} returned 202. Retrying...")
                    print(f"A path returned 202. Retrying...")
                    await asyncio.sleep(2)
                    continue

                result = await r_async.json()
                if result is not None:
                    return result
            except:
                print("aiohttp failed for rest query")
                # Fall back on non-async requests
                async with self.semaphore:
                    r_requests = requests.get(
                        f"https://api.github.com/{path}",
                        headers=headers,
                        params=tuple(params.items()),
                    )
                    if r_requests.status_code == 202:
                        print(f"A path returned 202. Retrying...")
                        await asyncio.sleep(2)
                        continue
                    elif r_requests.status_code == 200:
                        return r_requests.json()
        # print(f"There were too many 202s. Data for {path} will be incomplete.")
        print("There were too many 202s. Data for this repository will be incomplete.")
        return dict()

    @staticmethod
    def repos_overview(
        contrib_cursor: Optional[str] = None, owned_cursor: Optional[str] = None
    ) -> str:
        """
        :return: GraphQL query with overview of user repositories
        """
        return f"""{{
            viewer {{
                login,
                name,
                repositories(
                    first: 100,
                    orderBy: {{
                        field: UPDATED_AT,
                        direction: DESC
                    }},
                    isFork: false,
                    after: {"null" if owned_cursor is None else '"' + owned_cursor + '"'}
                ) {{
                pageInfo {{
                    hasNextPage
                    endCursor
                }}
                nodes {{
                    nameWithOwner
                    stargazers {{
                    totalCount
                    }}
                    forkCount
                    languages(first: 10, orderBy: {{field: SIZE, direction: DESC}}) {{
                    edges {{
                        size
                        node {{
                        name
                        color
                        }}
                    }}
                    }}
                }}
                }}
                repositoriesContributedTo(
                    first: 100,
                    includeUserRepositories: false,
                    orderBy: {{
                        field: UPDATED_AT,
                        direction: DESC
                    }},
                    contributionTypes: [
                        COMMIT,
                        PULL_REQUEST,
                        REPOSITORY,
                        PULL_REQUEST_REVIEW
                    ]
                    after: {"null" if contrib_cursor is None else '"' + contrib_cursor + '"'}
                ) {{
                pageInfo {{
                    hasNextPage
                    endCursor
                }}
                nodes {{
                    nameWithOwner
                    stargazers {{
                    totalCount
                    }}
                    forkCount
                    languages(first: 10, orderBy: {{field: SIZE, direction: DESC}}) {{
                    edges {{
                        size
                        node {{
                        name
                        color
                        }}
                    }}
                    }}
                }}
                }}
            }}
            }}
        """

    @staticmethod
    def contrib_years() -> str:
        """
        :return: GraphQL query to get all years the user has been a contributor
        """
        return """
query {
  viewer {
    contributionsCollection {
      contributionYears
    }
  }
}
"""

    @staticmethod
    def contribs_by_year(year: str) -> str:
        """
        :param year: year to query for
        :return: portion of a GraphQL query with desired info for a given year
        """
        return f"""
    year{year}: contributionsCollection(
        from: "{year}-01-01T00:00:00Z",
        to: "{int(year) + 1}-01-01T00:00:00Z"
    ) {{
      contributionCalendar {{
        totalContributions
      }}
    }}
"""

    @classmethod
    def all_contribs(cls, years: List[str]) -> str:
        """
        :param years: list of years to get contributions for
        :return: query to retrieve contribution information for all user years
        """
        by_years = "\n".join(map(cls.contribs_by_year, years))
        return f"""
query {{
  viewer {{
    {by_years}
  }}
}}
"""


class Stats(object):
    """
    Retrieve and store statistics about GitHub usage.
    """

    def __init__(
        self,
        username: str,
        access_token: str,
        session: aiohttp.ClientSession,
        exclude_repos: Optional[Set] = None,
        exclude_langs: Optional[Set] = None,
        ignore_forked_repos: bool = False,
    ):
        self.username = username
        self._ignore_forked_repos = ignore_forked_repos
        self._exclude_repos = set() if exclude_repos is None else exclude_repos
        self._exclude_langs = set() if exclude_langs is None else exclude_langs
        self.queries = Queries(username, access_token, session)

        self._name: Optional[str] = None
        self._stargazers: Optional[int] = None
        self._forks: Optional[int] = None
        self._total_contributions: Optional[int] = None
        self._languages: Optional[Dict[str, Any]] = None
        self._repos: Optional[Set[str]] = None
        self._lines_changed: Optional[Tuple[int, int]] = None
        self._views: Optional[int] = None


    async def to_str(self) -> str:
        """
        :return: summary of all available statistics
        """
        languages = await self.languages_proportional
        formatted_languages = "\n  - ".join(
            [f"{k}: {v:0.4f}%" for k, v in languages.items()]
        )
        lines_changed = await self.lines_changed
        return f"""Name: {await self.name}
            Stargazers: {await self.stargazers:,}
            Forks: {await self.forks:,}
            All-time contributions: {await self.total_contributions:,}
            Repositories with contributions: {len(await self.repos)}
            Lines of code added: {lines_changed[0]:,}
            Lines of code deleted: {lines_changed[1]:,}
            Lines of code changed: {lines_changed[0] + lines_changed[1]:,}
            Project page views: {await self.views:,}
            Languages:
            - {formatted_languages}
            """


    async def get_stats(self) -> None:
        """
        Get lots of summary statistics using one big query. Sets many attributes
        """
        self._stargazers = 0
        self._forks = 0
        self._languages = dict()
        self._repos = set()

        exclude_langs_lower = {x.lower() for x in self._exclude_langs}

        next_owned = None
        next_contrib = None
        while True:
            raw_results = await self.queries.query(
                Queries.repos_overview(
                    owned_cursor=next_owned, contrib_cursor=next_contrib
                )
            )
            raw_results = raw_results if raw_results is not None else {}

            self._name = raw_results.get("data", {}).get("viewer", {}).get("name", None)
            if self._name is None:
                self._name = (
                    raw_results.get("data", {})
                    .get("viewer", {})
                    .get("login", "No Name")
                )

            contrib_repos = (
                raw_results.get("data", {})
                .get("viewer", {})
                .get("repositoriesContributedTo", {})
            )
            owned_repos = (
                raw_results.get("data", {}).get("viewer", {}).get("repositories", {})
            )

            repos = owned_repos.get("nodes", [])
            if not self._ignore_forked_repos:
                repos += contrib_repos.get("nodes", [])

            for repo in repos:
                if repo is None:
                    continue
                name = repo.get("nameWithOwner")
                if name in self._repos or name in self._exclude_repos:
                    continue
                self._repos.add(name)
                self._stargazers += repo.get("stargazers").get("totalCount", 0)
                self._forks += repo.get("forkCount", 0)

                for lang in repo.get("languages", {}).get("edges", []):
                    name = lang.get("node", {}).get("name", "Other")
                    languages = await self.languages
                    if name.lower() in exclude_langs_lower:
                        continue
                    if name in languages:
                        languages[name]["size"] += lang.get("size", 0)
                        languages[name]["occurrences"] += 1
                    else:
                        languages[name] = {
                            "size": lang.get("size", 0),
                            "occurrences": 1,
                            "color": lang.get("node", {}).get("color"),
                        }

            if owned_repos.get("pageInfo", {}).get(
                "hasNextPage", False
            ) or contrib_repos.get("pageInfo", {}).get("hasNextPage", False):
                next_owned = owned_repos.get("pageInfo", {}).get(
                    "endCursor", next_owned
                )
                next_contrib = contrib_repos.get("pageInfo", {}).get(
                    "endCursor", next_contrib
                )
            else:
                break

        # TODO: Improve languages to scale by number of contributions to
        #       specific filetypes
        langs_total = sum([v.get("size", 0) for v in self._languages.values()])
        for k, v in self._languages.items():
            v["prop"] = 100 * (v.get("size", 0) / langs_total)


    @property
    async def name(self) -> str:
        """
        :return: GitHub user's name (e.g., Jacob Strieb)
        """
        if self._name is not None:
            return self._name
        await self.get_stats()
        assert self._name is not None
        return self._name


    @property
    async def stargazers(self) -> int:
        """
        :return: total number of stargazers on user's repos
        """
        if self._stargazers is not None:
            return self._stargazers
        await self.get_stats()
        assert self._stargazers is not None
        return self._stargazers


    @property
    async def forks(self) -> int:
        """
        :return: total number of forks on user's repos
        """
        if self._forks is not None:
            return self._forks
        await self.get_stats()
        assert self._forks is not None
        return self._forks


    @property
    async def languages(self) -> Dict:
        """
        :return: summary of languages used by the user
        """
        if self._languages is not None:
            return self._languages
        await self.get_stats()
        assert self._languages is not None
        return self._languages


    @property
    async def languages_proportional(self) -> Dict:
        """
        :return: summary of languages used by the user, with proportional usage
        """
        if self._languages is None:
            await self.get_stats()
            assert self._languages is not None

        return {k: v.get("prop", 0) for (k, v) in self._languages.items()}


    @property
    async def repos(self) -> Set[str]:
        """
        :return: list of names of user's repos
        """
        if self._repos is not None:
            return self._repos
        await self.get_stats()
        assert self._repos is not None
        return self._repos


    @property
    async def total_contributions(self) -> int:
        """
        :return: count of user's total contributions as defined by GitHub
        """
        if self._total_contributions is not None:
            return self._total_contributions

        self._total_contributions = 0
        years = (
            (await self.queries.query(Queries.contrib_years()))
            .get("data", {})
            .get("viewer", {})
            .get("contributionsCollection", {})
            .get("contributionYears", [])
        )
        by_year = (
            (await self.queries.query(Queries.all_contribs(years)))
            .get("data", {})
            .get("viewer", {})
            .values()
        )
        for year in by_year:
            self._total_contributions += year.get("contributionCalendar", {}).get(
                "totalContributions", 0
            )
        return cast(int, self._total_contributions)


    @property
    async def lines_changed(self):
        """
        :return: total lines added and deleted by the user.
        - First run: full scan.
        - Next runs: incremental update.
        """
        cache = load_cache()
        lc = get_lines_changed(cache)

        if not lc:
            additions = 0
            deletions = 0

            for repo in await self.repos:
                r = await self.queries.query_rest(f"/repos/{repo}/stats/contributors")
                if not isinstance(r, list):
                    continue

                for author_obj in r:
                    author = author_obj.get("author", {}).get("login")
                    if author != self.username:
                        continue
                    for week in author_obj.get("weeks", []):
                        additions += week.get("a", 0)
                        deletions += week.get("d", 0)

            now = datetime.utcnow().isoformat() + "Z"
            cache = set_lines_changed(cache, additions, deletions, now)
            save_cache(cache)

            self._lines_changed = (additions, deletions)
            return self._lines_changed

        additions = lc["additions"]
        deletions = lc["deletions"]
        since = lc["last_commit_date"]

        delta_add, delta_del, newest = await self.lines_changed_since(since)

        if delta_add == 0 and delta_del == 0:
            self._lines_changed = (additions, deletions)
            return self._lines_changed

        additions += delta_add
        deletions += delta_del

        cache = set_lines_changed(cache, additions, deletions, newest)
        save_cache(cache)

        self._lines_changed = (additions, deletions)
        return self._lines_changed


    @property
    async def views(self) -> int:
        """
        Note: only returns views for the last 14 days (as-per GitHub API)
        :return: total number of page views the user's projects have received
        """
        if self._views is not None:
            return self._views

        total = 0
        for repo in await self.repos:
            r = await self.queries.query_rest(f"/repos/{repo}/traffic/views")
            for view in r.get("views", []):
                total += view.get("count", 0)

        self._views = total
        return total


    async def lines_changed_since(self, since_iso: str):
        """
        Retrieve incremental lines added and deleted since a given timestamp.
        Used for incremental lines_changed calculation.
        """
        additions = 0
        deletions = 0
        newest_commit_date = since_iso

        since_dt = datetime.fromisoformat(since_iso.replace("Z", "+00:00"))

        events = await self.queries.query_rest(
            f"/users/{self.username}/events"
        )

        for event in events:
            if event.get("type") != "PushEvent":
                continue

            for commit in event["payload"].get("commits", []):
                repo = event["repo"]["name"]
                sha = commit["sha"]

                data = await self.queries.query_rest(
                    f"/repos/{repo}/commits/{sha}"
                )
                if not data or "commit" not in data:
                    continue

                commit_iso = data["commit"]["author"]["date"]
                commit_dt = datetime.fromisoformat(
                    commit_iso.replace("Z", "+00:00"))

                if commit_dt <= since_dt:
                    continue

                stats = data.get("stats")
                if not stats:
                    continue

                additions += stats.get("additions", 0)
                deletions += stats.get("deletions", 0)

                if commit_iso > newest_commit_date:
                    newest_commit_date = commit_iso

        return additions, deletions, newest_commit_date

    async def yearly_activity_month_slots(self, year: int):
        """
        :Returns fixed 48 slots (12 months x 4 slots).
        - summed contributions as value
        - Future as none
        """
        days = await self.yearly_activity_daily(year)
        today = datetime.utcnow().date()

        by_month = {m: [] for m in range(1, 13)}
        for d in days:
            d_date = datetime.fromisoformat(d["date"]).date()
            by_month[d_date.month].append({
                "day": d_date.day,
                "count": d["count"],
                "is_future": d_date > today,
            })

        slots = []

        for month in range(1, 13):
            days_in_month = calendar.monthrange(year, month)[1]
            slot_size = math.ceil(days_in_month / 4)

            month_slots = [0, 0, 0, 0]
            future_mask = [True, True, True, True]

            for item in by_month[month]:
                slot_idx = min((item["day"] - 1) // slot_size, 3)

                if item["is_future"]:
                    continue

                future_mask[slot_idx] = False
                month_slots[slot_idx] += item["count"]

            # convert future-only slots â†’ None
            for i in range(4):
                if future_mask[i]:
                    month_slots[i] = None

            slots.extend(month_slots)

        assert len(slots) == 48
        return slots

    async def yearly_activity_daily(self, year: int):
        """
        Retrieve daily contribution counts for a given year.
        Used for activity graph generation.
        """
        query = f"""
        query {{
        viewer {{
            contributionsCollection(
            from: "{year}-01-01T00:00:00Z",
            to: "{year + 1}-01-01T00:00:00Z"
            ) {{
            contributionCalendar {{
                weeks {{
                contributionDays {{
                    date
                    contributionCount
                }}
                }}
            }}
            }}
        }}
        }}
        """

        # TODO: Cache per-year daily activity to avoid repeated GraphQL queries
        #       when regenerating activity graphs.
        result = await self.queries.query(query)

        days = []
        for w in result["data"]["viewer"]["contributionsCollection"]["contributionCalendar"]["weeks"]:
            for d in w["contributionDays"]:
                d_year = datetime.fromisoformat(d["date"]).year
                if d_year == year:
                    days.append({
                        "date": d["date"],
                        "count": d["contributionCount"]
                    })

        return days

    async def recent_commits(self, limit: int = 3):
        """
        :return: list of recent commit objects.
        - First run: fetch & cache
        - Next runs: incremental via fingerprints
        """
        cache = load_cache()
        cached = get_recent_commits(cache)
        old_fps = cached["fingerprints"] if cached else []

        new_fps = await self.recent_commit_fingerprints(limit)

        if not old_fps and not new_fps:
            cache = set_recent_commits(cache, [])
            save_cache(cache)
            return []

        # TODO: Fingerprints are heuristic-based; force-push or rebase
        #       may invalidate cached commit ordering.
        if old_fps and new_fps == old_fps:
            return await self.fetch_commit_details(old_fps)

        commits = await self.fetch_commit_details(new_fps)

        cache = set_recent_commits(cache, new_fps)
        save_cache(cache)

        return commits


    async def recent_commit_fingerprints(self, limit: int = 3):
        """
        Lightweight check using Events API.
        Returns latest commit fingerprints in format: owner/repo@short_sha.
        """
        events = await self.queries.query_rest(
            f"/users/{self.username}/events"
        )

        fingerprints = []

        for event in events:
            if event.get("type") != "PushEvent":
                continue

            repo = event["repo"]["name"]

            # TODO: Only the head commit of a PushEvent is used;
            #       intermediate commits in the same push are ignored.
            head = event["payload"].get("head")
            if not head:
                continue
            sha = head[:7]
            fp = f"{repo}@{sha}"

            if fp not in fingerprints:
                fingerprints.append(fp)

            if len(fingerprints) >= limit:
                break

        return fingerprints


    async def fetch_commit_details(self, fingerprints):
        """
        Fetch detailed commit information from Commit API
        based on provided commit fingerprints.
        """
        commits = []

        # TODO: Performs one REST API call per commit (N+1);
        #       may hit rate limits for larger limits.
        for fp in fingerprints:
            repo_full, short_sha = fp.rsplit("@", 1)
            owner, repo = repo_full.split("/")

            data = await self.queries.query_rest(
                f"/repos/{owner}/{repo}/commits/{short_sha}"
            )

            if not data or "commit" not in data:
                continue

            commits.append({
                "repo": f"{owner}/{repo}",
                "message": data["commit"]["message"].split("\n")[0],
                "author": data["commit"]["author"]["name"],
                "date": data["commit"]["author"]["date"],
                "sha": short_sha,
            })

        return commits



###############################################################################
# Main Function
###############################################################################


async def main() -> None:
    """
    Used mostly for testing; this module is not usually run standalone
    """
    access_token = os.getenv("ACCESS_TOKEN")
    user = os.getenv("GITHUB_ACTOR")
    if access_token is None or user is None:
        raise RuntimeError(
            "ACCESS_TOKEN and GITHUB_ACTOR environment variables cannot be None!"
        )
    async with aiohttp.ClientSession() as session:
        s = Stats(user, access_token, session)
        print(await s.to_str())


if __name__ == "__main__":
    asyncio.run(main())
